{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Project: Refining the Art of Sentiment Analysis at ModaMetric\n",
    "\n",
    "Welcome to Week 2! The ModaMetric team is still buzzing from the achievements of last week. You've shown them the power of Metaflow and the potential of machine learning. However, there's more to explore, more to refine.\n",
    "\n",
    "Once again, weâ€™ll delve into the [Women's Ecommerce Clothing Reviews Dataset from Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews), the dataset that helped us unlock valuable insights for ModaMetric. Your mission is to further refine the sentiment analysis process, enabling ModaMetric to better understand the sentiments embedded in the customer reviews.\n",
    "\n",
    "## Task 1: Orchestrating the Dance of Sentiment Analysis Models with Metaflow\n",
    "\n",
    "In this task, you'll utilize Metaflow to train two sentiment analysis models: the baseline \"majority class\" classifier and your own custom model. The models will be trained simultaneously, flexing the power of Metaflow. Your task also involves tweaking the models' hyperparameters for optimal performance. Finally, you'll analyze the performance of these models using Metaflow's Client API. Here's how you'll proceed:\n",
    "\n",
    "### Step 1: Constructing the Sentiment Analysis Workflows\n",
    "Your first task is to construct the Metaflow workflows. Begin with the baseline \"majority class\" classifier and then move on to your custom model. Make sure your custom model includes steps for data preprocessing, model training, and evaluation. Feel free to use techniques from Week 1 and any other [resources](https://outerbounds.com/docs/nlp-tutorial-L2/) you find useful.\n",
    "\n",
    "### Step 2: Parallel Training of Models\n",
    "Having built the models, you'll use Metaflow to train them simultaneously. The race is on - can the custom model outshine the baseline? If you find yourself in a bind, you might find the [FlowSpec branching documentation](https://docs.metaflow.org/metaflow/basics#branch) useful.\n",
    "\n",
    "### Step 3: The Hyperparameters Experiment\n",
    "Once you've trained the models, it's time for some fine-tuning. Experiment with different hyperparameters such as learning rate, batch size, and number of epochs. Record the performance of each model under different hyperparameter combinations as Data Artifacts in Metaflow.\n",
    "\n",
    "### Step 4: Results Analysis\n",
    "With the experiments complete, it's time to analyze the results. Use Metaflow's Client API to fetch the data and create visualizations to compare the models' performances. The goal is to identify the best hyperparameters for each model.\n",
    "\n",
    "By completing this task, you're not only refining the sentiment analysis process at ModaMetric but also honing your own skills in orchestrating complex machine learning workflows using Metaflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "# You can style your plots here, but it is not part of the project.\n",
    "YELLOW = \"#FFBC00\"\n",
    "GREEN = \"#37795D\"\n",
    "PURPLE = \"#5460C0\"\n",
    "BACKGROUND = \"#F4EBE6\"\n",
    "colors = [GREEN, PURPLE]\n",
    "custom_params = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.facecolor\": BACKGROUND,\n",
    "    \"figure.facecolor\": BACKGROUND,\n",
    "    \"figure.figsize\": (8, 8),\n",
    "}\n",
    "sns_palette = sns.color_palette(colors, len(colors))\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load the data.\n",
    "df = pd.read_csv('../data/Womens Clothing E-Commerce Reviews.csv', index_col=0)\n",
    "# df = pd.read_csv('../data/Womens Clothing E-Commerce Reviews.csv')\n",
    "\n",
    "# the labeling function\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# transformations\n",
    "df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "df = df[~df.review_text.isna()]\n",
    "df[\"review\"] = df[\"review_text\"].astype(\"str\")\n",
    "_has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "reviews = _has_review_df[\"review_text\"]\n",
    "labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "# split into training and validation.\n",
    "_df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "traindf, valdf = train_test_split(_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17448\n",
       "0     5193\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7739015235151248\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# TODO: build the majority class baseline model.\n",
    "# TODO: find the majority class in the labels. ðŸ¤”\n",
    "# TODO: score the model on valdf with a 2D metric space: sklearn.metrics.accuracy_score, sklearn.metrics.roc_auc_score\n",
    "# Documentation on suggested model-scoring approach: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "traindf['model'] = 1\n",
    "valdf['model'] = 1\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "base_acc = accuracy_score(valdf['label'].to_numpy(), valdf['model'].to_numpy())\n",
    "base_rocauc = roc_auc_score(valdf['label'].to_numpy(), valdf['model'].to_numpy())\n",
    "\n",
    "print(base_acc)\n",
    "print(base_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4529"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf.head(3)\n",
    "len(valdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18112"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head(3)\n",
    "len(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4529"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(valdf[~valdf.review.isna()])\n",
    "len(valdf[~valdf.review.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18112"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(traindf[~traindf.review.isna()])\n",
    "len(traindf[~traindf.review.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "# TODO: modify this custom model to your liking. Check out this tutorial for more on this class: https://outerbounds.com/docs/nlp-tutorial-L2/\n",
    "# TODO: train the model on traindf.\n",
    "# TODO: score the model on valdf with _the same_ 2D metric space you used in previous cell.\n",
    "# TODO: test your model works by importing the model module in notebook cells, and trying to fit traindf and score predictions on the valdf data!\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class NbowModel:\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "\n",
    "        # Instantiate the CountVectorizer\n",
    "        self.cv = CountVectorizer(\n",
    "            min_df=0.005,\n",
    "            max_df=0.75,\n",
    "            stop_words=\"english\",\n",
    "            strip_accents=\"ascii\",\n",
    "            max_features=self.vocab_sz,\n",
    "        )\n",
    "\n",
    "        # Define the keras model\n",
    "        inputs = tf.keras.Input(shape=(self.vocab_sz,), name=\"input\")\n",
    "        x = layers.Dropout(0.10)(inputs)\n",
    "        x = layers.Dense(\n",
    "            15,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "        )(x)\n",
    "        predictions = layers.Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\",\n",
    "        )(x)\n",
    "        self.model = tf.keras.Model(inputs, predictions)\n",
    "        opt = optimizers.Adam(learning_rate=0.002)\n",
    "        self.model.compile(\n",
    "            loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(X.shape)\n",
    "        print(X[0])\n",
    "        res = self.cv.fit_transform(X).toarray()\n",
    "        self.model.fit(x=res, y=y, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(X.shape)\n",
    "        print(X[0])\n",
    "        res = self.cv.transform(X).toarray()\n",
    "        return self.model.predict(res)\n",
    "\n",
    "    def eval_acc(self, X, labels, threshold=0.5):\n",
    "        return accuracy_score(labels, self.predict(X) > threshold)\n",
    "\n",
    "    def eval_rocauc(self, X, labels):\n",
    "        return roc_auc_score(labels, self.predict(X))\n",
    "\n",
    "    @property\n",
    "    def model_dict(self):\n",
    "        return {\"vectorizer\": self.cv, \"model\": self.model}\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, model_dict):\n",
    "        \"Get Model from dictionary\"\n",
    "        nbow_model = cls(len(model_dict[\"vectorizer\"].vocabulary_))\n",
    "        nbow_model.model = model_dict[\"model\"]\n",
    "        nbow_model.cv = model_dict[\"vectorizer\"]\n",
    "        return nbow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18112,)\n",
      "I immediately loved the rich royal blue color of this sweater with its pretty flower, nice fabric and medium weight. nice warm sweater.i have an retailer skirt just like the photo, great outfit. i am happy i ordered it, but hope it shrinks after washing.the small is very big and boxy, sleeves long. i am 5'6 medium build. small usually fits me well.\n",
      "i recommend downsizing or you will probably take this back.\n",
      "Epoch 1/10\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.3967 - accuracy: 0.8330 - val_loss: 0.3532 - val_accuracy: 0.8463\n",
      "Epoch 2/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8629 - val_loss: 0.3507 - val_accuracy: 0.8485\n",
      "Epoch 3/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8667 - val_loss: 0.3540 - val_accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8708 - val_loss: 0.3600 - val_accuracy: 0.8490\n",
      "Epoch 5/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8756 - val_loss: 0.3529 - val_accuracy: 0.8532\n",
      "Epoch 6/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2904 - accuracy: 0.8794 - val_loss: 0.3602 - val_accuracy: 0.8463\n",
      "Epoch 7/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.8871 - val_loss: 0.3676 - val_accuracy: 0.8471\n",
      "Epoch 8/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2719 - accuracy: 0.8923 - val_loss: 0.3675 - val_accuracy: 0.8485\n",
      "Epoch 9/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9005 - val_loss: 0.3775 - val_accuracy: 0.8507\n",
      "Epoch 10/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.9029 - val_loss: 0.3800 - val_accuracy: 0.8490\n"
     ]
    }
   ],
   "source": [
    "from model import NbowModel\n",
    "import pandas as pd\n",
    "my_model = NbowModel(vocab_sz=600)\n",
    "my_model.fit(X=traindf['review'].values, y=traindf['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4529,)\n",
      "Just bought this in the store a couple days ago and wore it for the first time today. love the embroidery detail and i feel that the colors are more vibrant in person. i typically wear a 2 in most retailer tops but i got a 0 in this and it is great - seems to be a generous fit. the slits on the sides do come up a bit high, but i wore a cami underneath since it is sheer and the slits were not an issue with it. looks great with jeans. it is a great transitional piece for the fall as i'm sure i will\n",
      "142/142 [==============================] - 0s 981us/step\n",
      "(4529,)\n",
      "Just bought this in the store a couple days ago and wore it for the first time today. love the embroidery detail and i feel that the colors are more vibrant in person. i typically wear a 2 in most retailer tops but i got a 0 in this and it is great - seems to be a generous fit. the slits on the sides do come up a bit high, but i wore a cami underneath since it is sheer and the slits were not an issue with it. looks great with jeans. it is a great transitional piece for the fall as i'm sure i will\n",
      "142/142 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8540516670346655, 0.8964149986626248)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.eval_acc(valdf.review.values, valdf.label), my_model.eval_rocauc(valdf.review.values, valdf.label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[254], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mtype\u001b[39m(traindf[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m2\u001b[39;49m])\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "type(traindf['label'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have several of these shirts and love them. i can dress them up or down, and they look great. comfortable and soft, and lose enough to be flattering but not bulky. great buy!\n"
     ]
    }
   ],
   "source": [
    "print(valdf['review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[250], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mtype\u001b[39m(valdf[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "type(valdf['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[242], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mtype\u001b[39m(valdf[\u001b[39m'\u001b[39;49m\u001b[39mreview\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "type(valdf['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(valdf['review'][72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['review'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following line results in an error but the next one works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4529,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[39m=\u001b[39m my_model\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mvaldf[\u001b[39m'\u001b[39;49m\u001b[39mreview\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/workspaces/full-stack-ml-metaflow-corise-week-2/project/model.py:52\u001b[0m, in \u001b[0;36mNbowModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     51\u001b[0m     \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mprint\u001b[39m(X[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     53\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv\u001b[39m.\u001b[39mtransform(X)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(res)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "preds = my_model.predict(X=valdf['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4529,)\n",
      "Just bought this in the store a couple days ago and wore it for the first time today. love the embroidery detail and i feel that the colors are more vibrant in person. i typically wear a 2 in most retailer tops but i got a 0 in this and it is great - seems to be a generous fit. the slits on the sides do come up a bit high, but i wore a cami underneath since it is sheer and the slits were not an issue with it. looks great with jeans. it is a great transitional piece for the fall as i'm sure i will\n",
      "142/142 [==============================] - 0s 951us/step\n"
     ]
    }
   ],
   "source": [
    "preds = my_model.predict(X=valdf['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4529,)\n",
      "Just bought this in the store a couple days ago and wore it for the first time today. love the embroidery detail and i feel that the colors are more vibrant in person. i typically wear a 2 in most retailer tops but i got a 0 in this and it is great - seems to be a generous fit. the slits on the sides do come up a bit high, but i wore a cami underneath since it is sheer and the slits were not an issue with it. looks great with jeans. it is a great transitional piece for the fall as i'm sure i will\n",
      "142/142 [==============================] - 0s 972us/step\n",
      "(4529,)\n",
      "Just bought this in the store a couple days ago and wore it for the first time today. love the embroidery detail and i feel that the colors are more vibrant in person. i typically wear a 2 in most retailer tops but i got a 0 in this and it is great - seems to be a generous fit. the slits on the sides do come up a bit high, but i wore a cami underneath since it is sheer and the slits were not an issue with it. looks great with jeans. it is a great transitional piece for the fall as i'm sure i will\n",
      "142/142 [==============================] - 0s 919us/step\n",
      "Baseline Accuracy: 0.905\n",
      "Baseline AUC: 0.947\n"
     ]
    }
   ],
   "source": [
    "model_acc = model.eval_acc(valdf['review'].values, valdf['label'].values)\n",
    "model_rocauc = model.eval_rocauc(valdf['review'].values, valdf['label'].values)\n",
    "\n",
    "msg = 'Baseline Accuracy: {}\\nBaseline AUC: {}'\n",
    "print(msg.format(\n",
    "    round(model_acc, 3), round(model_rocauc, 3)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting baseline_challenge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile baseline_challenge.py\n",
    "# TODO: In this cell, write your BaselineChallenge flow in the baseline_challenge.py file.\n",
    "\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Flow,\n",
    "    current,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current,\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact, Image\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# TODO: Define your labeling function here.\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelResult:\n",
    "    \"A custom struct for storing model evaluation results.\"\n",
    "    name: None\n",
    "    params: None\n",
    "    pathspec: None\n",
    "    acc: None\n",
    "    rocauc: None\n",
    "\n",
    "\n",
    "class BaselineChallenge(FlowSpec):\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    data = IncludeFile(\"data\", default=\"Womens Clothing E-Commerce Reviews.csv\")\n",
    "    kfold = Parameter(\"k\", default=5)\n",
    "    scoring = Parameter(\"scoring\", default=\"accuracy\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # load dataset packaged with the flow.\n",
    "        # this technique is convenient when working with small datasets that need to move to remove tasks.\n",
    "        # TODO: load the data.\n",
    "        df = pd.read_csv(io.StringIO(self.data), index_col=0)\n",
    "        # df = pd.read_csv('../data/Womens Clothing E-Commerce Reviews.csv', index_col=0)\n",
    "\n",
    "        # Look up a few lines to the IncludeFile('data', default='Womens Clothing E-Commerce Reviews.csv').\n",
    "        # You can find documentation on IncludeFile here: https://docs.metaflow.org/scaling/data#data-in-local-files\n",
    "\n",
    "        # filter down to reviews and labels\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df = df[~df.review_text.isna()]\n",
    "        df[\"review\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "        # split the data 80/20, or by using the flow's split-sz CLI argument\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, test_size=self.split_size)\n",
    "        print(f\"num of rows in train set: {self.traindf.shape[0]}\")\n",
    "        print(f\"num of rows in validation set: {self.valdf.shape[0]}\")\n",
    "\n",
    "        self.next(self.baseline, self.model)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "        self._name = \"baseline\"\n",
    "        params = \"Always predict 1\"\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        # TODO: predict the majority class\n",
    "        predictions = [1] * len(self.valdf)\n",
    "        # TODO: return the accuracy_score of these predictions\n",
    "        acc = accuracy_score(self.valdf.label, predictions)\n",
    "\n",
    "        # TODO: return the roc_auc_score of these predictions\n",
    "        rocauc = roc_auc_score(self.valdf.label, predictions)\n",
    "        self.result = ModelResult(\"Baseline\", params, pathspec, acc, rocauc)\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def model(self):\n",
    "        # TODO: import your model if it is defined in another file.\n",
    "        from model import NbowModel\n",
    "\n",
    "        self._name = \"model\"\n",
    "        # NOTE: If you followed the link above to find a custom model implementation,\n",
    "        # you will have noticed your model's vocab_sz hyperparameter.\n",
    "        # Too big of vocab_sz causes an error. Can you explain why?\n",
    "        self.hyperparam_set = [{\"vocab_sz\": 100}, {\"vocab_sz\": 300}, {\"vocab_sz\": 500}]\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        self.results = []\n",
    "        for params in self.hyperparam_set:\n",
    "            model = NbowModel(**params)  # TODO: instantiate your custom model here!\n",
    "            model.fit(X=self.df[\"review\"], y=self.df[\"label\"])\n",
    "            # TODO: evaluate your custom model in an equivalent way to accuracy_score.\n",
    "            acc = model.eval_acc(self.valdf.review.values, self.valdf.label) \n",
    "            # TODO: evaluate your custom model in an equivalent way to roc_auc_score.\n",
    "            rocauc = model.eval_rocauc(self.valdf.review.values, self.valdf.label) \n",
    "            self.results.append(\n",
    "                ModelResult(\n",
    "                    f\"NbowModel - vocab_sz: {params['vocab_sz']}\",\n",
    "                    params,\n",
    "                    pathspec,\n",
    "                    acc,\n",
    "                    rocauc,\n",
    "                )\n",
    "            )\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "    @card\n",
    "    @step\n",
    "    def aggregate(self, inputs):\n",
    "        # For some reason, not able to access the following using the Metaflow client API \n",
    "        # self.baseline_result = inputs.baseline.result\n",
    "        # self.model_result = inputs.model.results\n",
    "\n",
    "        self.baseline_result = self.result\n",
    "        self.model_result = self.results\n",
    "\n",
    "        # This is a workaround for the not being able to acccess the above properties \n",
    "        # using the client API \n",
    "        self.results = {}\n",
    "        self.result[\"baseline_result\"] = asdict(inputs.baseline.result)\n",
    "        self.result[\"model_results\"] = []\n",
    "        for res in inputs.model.results:\n",
    "            self.result[\"model_results\"].append(asdict(res))\n",
    "\n",
    "        # Am able to access the following using the Metaflow client API \n",
    "        self.test1 = 'a'\n",
    "        self.test2 = {\"key1\": \"Jim\", \"key2\": \"Smith\"}\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Reached end\")\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BaselineChallenge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.7.2+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mBaselineChallenge\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mIncluding file ../data/Womens Clothing E-Commerce Reviews.csv of size 8MB \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:50.472 \u001b[0m\u001b[1mWorkflow starting (run-id 10), see it in the UI at https://ui-pw-906649423.outerbounds.dev/BaselineChallenge/10\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:50.876 \u001b[0m\u001b[32m[10/start/55 (pid 22319)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:55.052 \u001b[0m\u001b[32m[10/start/55 (pid 22319)] \u001b[0m\u001b[22mnum of rows in train set: 18112\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:59.000 \u001b[0m\u001b[32m[10/start/55 (pid 22319)] \u001b[0m\u001b[22mnum of rows in validation set: 4529\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:59.369 \u001b[0m\u001b[32m[10/start/55 (pid 22319)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:59.751 \u001b[0m\u001b[32m[10/baseline/56 (pid 22415)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:12:59.931 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:02.106 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22m2023-10-31 15:13:02.106739: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:05.880 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:05.880 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22m2023-10-31 15:13:05.880054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:06.521 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:06.521 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:07.039 \u001b[0m\u001b[32m[10/baseline/56 (pid 22415)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:07.772 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.7822 - val_loss: 0.4175 - val_accuracy: 0.8132\u001b[0m8323 - accuracy: 0.18\n",
      "\u001b[35m2023-10-31 15:13:09.371 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.8060 - val_loss: 0.4172 - val_accuracy: 0.8123\u001b[0m93 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:10.362 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.4097 - val_accuracy: 0.8198\u001b[0m33 - accuracy: 0.71\n",
      "\u001b[35m2023-10-31 15:13:11.287 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4143 - accuracy: 0.8141 - val_loss: 0.4091 - val_accuracy: 0.8227\u001b[0m33 - accuracy: 0.71\n",
      "\u001b[35m2023-10-31 15:13:12.247 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8153 - val_loss: 0.4099 - val_accuracy: 0.8185\u001b[0m56 - accuracy: 0.78\n",
      "\u001b[35m2023-10-31 15:13:13.167 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4080 - accuracy: 0.8153 - val_loss: 0.4082 - val_accuracy: 0.8198\u001b[0m88 - accuracy: 0.87\n",
      "\u001b[35m2023-10-31 15:13:14.055 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8226 - val_loss: 0.4084 - val_accuracy: 0.8212\u001b[0m40 - accuracy: 0.93\n",
      "\u001b[35m2023-10-31 15:13:14.963 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4045 - accuracy: 0.8186 - val_loss: 0.4065 - val_accuracy: 0.8238\u001b[0m31 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:15.877 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8229 - val_loss: 0.4153 - val_accuracy: 0.8163\u001b[0m38 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:16.784 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8195 - val_loss: 0.4099 - val_accuracy: 0.8187\u001b[0m98 - accuracy: 0.75\n",
      "142/142 [==============================] - 0s 860us/step\u001b[0m8)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: 11\n",
      "142/142 [==============================] - 0s 889us/step\u001b[0m8)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-31 15:13:18.844 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:20.052 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:20.053 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 2ms/step - loss: 0.4060 - accuracy: 0.8249 - val_loss: 0.3540 - val_accuracy: 0.8518\u001b[0m6859 - accuracy: 0.56\n",
      "\u001b[35m2023-10-31 15:13:21.596 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3557 - accuracy: 0.8465 - val_loss: 0.3499 - val_accuracy: 0.8549\u001b[0m73 - accuracy: 0.78\n",
      "\u001b[35m2023-10-31 15:13:22.568 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8531 - val_loss: 0.3484 - val_accuracy: 0.8518\u001b[0m37 - accuracy: 0.87\n",
      "\u001b[35m2023-10-31 15:13:23.536 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8546 - val_loss: 0.3471 - val_accuracy: 0.8563\u001b[0m40 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:24.532 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8632 - val_loss: 0.3459 - val_accuracy: 0.8558\u001b[0m25 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:25.590 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.8656 - val_loss: 0.3507 - val_accuracy: 0.8488\u001b[0m02 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:26.647 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3182 - accuracy: 0.8678 - val_loss: 0.3500 - val_accuracy: 0.8527\u001b[0m37 - accuracy: 0.65\n",
      "\u001b[35m2023-10-31 15:13:27.651 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8714 - val_loss: 0.3560 - val_accuracy: 0.8479\u001b[0m94 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:28.658 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8729 - val_loss: 0.3562 - val_accuracy: 0.8534\u001b[0m95 - accuracy: 0.87\n",
      "\u001b[35m2023-10-31 15:13:29.689 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8774 - val_loss: 0.3653 - val_accuracy: 0.8465\u001b[0m95 - accuracy: 0.96\n",
      "142/142 [==============================] - 0s 894us/step\u001b[0m8)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "142/142 [==============================] - 0s 868us/step\u001b[0m8)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-31 15:13:31.687 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:32.895 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:32.896 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 2ms/step - loss: 0.3981 - accuracy: 0.8272 - val_loss: 0.3418 - val_accuracy: 0.8578\u001b[0m7746 - accuracy: 0.15\n",
      "\u001b[35m2023-10-31 15:13:34.487 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8562 - val_loss: 0.3454 - val_accuracy: 0.8558\u001b[0m77 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:35.532 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8611 - val_loss: 0.3392 - val_accuracy: 0.8587\u001b[0m16 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:36.596 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8675 - val_loss: 0.3395 - val_accuracy: 0.8627\u001b[0m48 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:37.669 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8740 - val_loss: 0.3433 - val_accuracy: 0.8653\u001b[0m56 - accuracy: 0.81\n",
      "\u001b[35m2023-10-31 15:13:38.738 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3037 - accuracy: 0.8754 - val_loss: 0.3434 - val_accuracy: 0.8638\u001b[0m64 - accuracy: 0.84\n",
      "\u001b[35m2023-10-31 15:13:39.832 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2941 - accuracy: 0.8859 - val_loss: 0.3514 - val_accuracy: 0.8560\u001b[0m65 - accuracy: 1.00\n",
      "\u001b[35m2023-10-31 15:13:40.914 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8871 - val_loss: 0.3558 - val_accuracy: 0.8536\u001b[0m57 - accuracy: 0.87\n",
      "\u001b[35m2023-10-31 15:13:42.008 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8899 - val_loss: 0.3611 - val_accuracy: 0.8563\u001b[0m52 - accuracy: 0.93\n",
      "\u001b[35m2023-10-31 15:13:43.061 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.8958 - val_loss: 0.3703 - val_accuracy: 0.8545\u001b[0m24 - accuracy: 0.93\n",
      "142/142 [==============================] - 0s 907us/step\u001b[0m8)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "142/142 [==============================] - 0s 898us/step\u001b[0m8)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-31 15:13:48.679 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:48.992 \u001b[0m\u001b[32m[10/model/57 (pid 22418)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:49.529 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:51.806 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22m<flow BaselineChallenge step aggregate> failed:\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.378 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mInternal error\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.380 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mTraceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.380 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/cli.py\", line 1175, in main\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.380 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mstart(auto_envvar_prefix=\"METAFLOW\", obj=state)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.380 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/tracing_noop.py\", line 19, in wrapper_func\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.380 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mreturn func(args, kwargs)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.723 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/_vendor/click/core.py\", line 829, in __call__\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.723 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mreturn self.main(args, kwargs)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/_vendor/click/core.py\", line 782, in main\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mrv = self.invoke(ctx)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/_vendor/click/core.py\", line 1259, in invoke\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mreturn _process_result(sub_ctx.command.invoke(sub_ctx))\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/_vendor/click/core.py\", line 1066, in invoke\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mreturn ctx.invoke(self.callback, ctx.params)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.724 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/_vendor/click/core.py\", line 610, in invoke\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mreturn callback(args, kwargs)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/_vendor/click/decorators.py\", line 21, in new_func\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mreturn f(get_current_context(), args, kwargs)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/cli.py\", line 582, in step\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mtask.run_step(\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/task.py\", line 597, in run_step\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.725 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mself._exec_step_function(step_func, input_obj)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/task.py\", line 62, in _exec_step_function\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mstep_function(input_obj)\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/workspaces/full-stack-ml-metaflow-corise-week-2/project/baseline_challenge.py\", line 128, in aggregate\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mself.baseline_result = self.result\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mFile \"/home/workspace/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/flowspec.py\", line 229, in __getattr__\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mraise AttributeError(\"Flow %s has no attribute '%s'\" % (self.name, name))\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22mAttributeError: Flow BaselineChallenge has no attribute 'result'\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.726 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.788 \u001b[0m\u001b[32m[10/aggregate/58 (pid 23351)] \u001b[0m\u001b[1mTask failed.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.895 \u001b[0m\u001b[31m\u001b[1mWorkflow failed.\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.895 \u001b[0m\u001b[31m\u001b[1mTerminating 0 active tasks...\u001b[0m\n",
      "\u001b[35m2023-10-31 15:13:52.896 \u001b[0m\u001b[31m\u001b[1mFlushing logs...\u001b[0m\n",
      "\u001b[1m    Step failure\u001b[0m\u001b[22m:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    Step \u001b[0m\u001b[31m\u001b[1maggregate\u001b[0m\u001b[22m (task-id 58) failed.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python baseline_challenge.py run --data \"../data/Womens Clothing E-Commerce Reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<MetaflowData: baseline_result, model_result, name, result, test1, test2, split_size, scoring, kfold, data>\n",
      "a\n",
      "{'firstName': 'Jim', 'lastName': 'Smith'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'ModelResult' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(run\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtest1)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(run\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtest2)\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(run\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mbaseline_result)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/client/core.py:738\u001b[0m, in \u001b[0;36mMetaflowData.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 738\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_artifacts[name]\u001b[39m.\u001b[39;49mdata\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/client/core.py:906\u001b[0m, in \u001b[0;36mDataArtifact.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m meta \u001b[39m=\u001b[39m {\n\u001b[1;32m    896\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object[\u001b[39m\"\u001b[39m\u001b[39msha\u001b[39m\u001b[39m\"\u001b[39m]},\n\u001b[1;32m    897\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfo\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m     },\n\u001b[1;32m    904\u001b[0m }\n\u001b[1;32m    905\u001b[0m \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m:root:\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 906\u001b[0m     obj \u001b[39m=\u001b[39m filecache\u001b[39m.\u001b[39;49mget_artifact(ds_type, location[\u001b[39m6\u001b[39;49m:], meta, \u001b[39m*\u001b[39;49mcomponents)\n\u001b[1;32m    907\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39m# Older artifacts have a location information which we can use.\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     obj \u001b[39m=\u001b[39m filecache\u001b[39m.\u001b[39mget_artifact_by_location(\n\u001b[1;32m    910\u001b[0m         ds_type, location, meta, \u001b[39m*\u001b[39mcomponents\n\u001b[1;32m    911\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/client/filecache.py:207\u001b[0m, in \u001b[0;36mFileCache.get_artifact\u001b[0;34m(self, ds_type, ds_root, data_metadata, flow_name, run_id, step_name, task_id, name)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_artifact\u001b[39m(\n\u001b[1;32m    197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    198\u001b[0m     ds_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     name,\n\u001b[1;32m    206\u001b[0m ):\n\u001b[0;32m--> 207\u001b[0m     _, obj \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\n\u001b[1;32m    208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_artifacts(\n\u001b[1;32m    209\u001b[0m             ds_type,\n\u001b[1;32m    210\u001b[0m             ds_root,\n\u001b[1;32m    211\u001b[0m             data_metadata,\n\u001b[1;32m    212\u001b[0m             flow_name,\n\u001b[1;32m    213\u001b[0m             run_id,\n\u001b[1;32m    214\u001b[0m             step_name,\n\u001b[1;32m    215\u001b[0m             task_id,\n\u001b[1;32m    216\u001b[0m             [name],\n\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/datastore/task_datastore.py:370\u001b[0m, in \u001b[0;36mTaskDataStore.load_artifacts\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    365\u001b[0m names \u001b[39m=\u001b[39m to_load[key]\n\u001b[1;32m    366\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m names:\n\u001b[1;32m    367\u001b[0m     \u001b[39m# We unpickle everytime to have fully distinct objects (the user\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[39m# would not expect two artifacts with different names to actually\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[39m# be aliases of one another)\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[39myield\u001b[39;00m name, pickle\u001b[39m.\u001b[39;49mloads(blob)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'ModelResult' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "name = 'BaselineChallenge'\n",
    "run = Flow(name).latest_run\n",
    "print(run.successful)\n",
    "\n",
    "print(run.data)\n",
    "print(run.data.test1)\n",
    "print(run.data.test2)\n",
    "print(run.data.baseline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<MetaflowData: baseline_result, model_result, name, result, test1, test2, split_size, scoring, kfold, data>\n",
      "<class 'metaflow.client.core.MetaflowData'>\n",
      "DataArtifact('BaselineChallenge/6/aggregate/35/model_result')\n",
      "DataArtifact('BaselineChallenge/6/aggregate/35/model_result')\n",
      "a\n",
      "<class 'dict'>\n",
      "{'firstName': 'Jim', 'lastName': 'Smith'}\n",
      "0.2\n",
      "<MetaflowData: baseline_result, model_result, name, result, test1, test2, split_size, scoring, kfold, data>\n",
      "{'baseline_result': {'name': 'Baseline', 'params': 'Always predict 1', 'pathspec': 'BaselineChallenge/6/baseline/33', 'acc': 0.7778759107970854, 'rocauc': 0.5}, 'model_results': [{'name': 'NbowModel - vocab_sz: 100', 'params': {'vocab_sz': 100}, 'pathspec': 'BaselineChallenge/6/model/34', 'acc': 0.840141311547803, 'rocauc': 0.8613830781984223}, {'name': 'NbowModel - vocab_sz: 300', 'params': {'vocab_sz': 300}, 'pathspec': 'BaselineChallenge/6/model/34', 'acc': 0.8867299624641202, 'rocauc': 0.9339293503808261}, {'name': 'NbowModel - vocab_sz: 500', 'params': {'vocab_sz': 500}, 'pathspec': 'BaselineChallenge/6/model/34', 'acc': 0.9083682932214617, 'rocauc': 0.9496850856258985}]}\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "name = 'BaselineChallenge'\n",
    "run = Flow(name).latest_run\n",
    "print(run.successful)\n",
    "\n",
    "print(run['aggregate'].task.data)\n",
    "print(type(run['aggregate'].task.data))\n",
    "\n",
    "# print(run['aggregate'].task.data[\"baseline_result\"])\n",
    "\n",
    "print(run['aggregate'].task.data._artifacts['model_result'])\n",
    "\n",
    "print(repr(run['aggregate'].task.data._artifacts['model_result']))\n",
    "\n",
    "# print(str(run['aggregate'].task.data._artifacts['model_result'].asdict()))\n",
    "\n",
    "# a = run['aggregate'].task.data._artifacts['model_result'].data\n",
    "# type(a)\n",
    "\n",
    "a = run['aggregate'].task.data._artifacts['model_result']\n",
    "type(a)\n",
    "\n",
    "# a = run['aggregate'].task.data.model_result\n",
    "# type(a)\n",
    "\n",
    "type(run.data.test1)\n",
    "b = run.data.test1\n",
    "print(b)\n",
    "\n",
    "c = run.data.test2\n",
    "print(type(c))\n",
    "print(c)\n",
    "\n",
    "print(run.data.split_size)\n",
    "\n",
    "print(run.data)\n",
    "\n",
    "print(run.data.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow\n",
    "name = 'BaselineChallenge'\n",
    "run = Flow(name).latest_run\n",
    "print(run.successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Me\n",
      "a\n",
      "_artifacts : {'baseline_result': DataArtifact('BaselineChallenge/2/end/12/baseline_result'), 'model_result': DataArtifact('BaselineChallenge/2/end/12/model_result'), 'name': DataArtifact('BaselineChallenge/2/end/12/name'), 'some': DataArtifact('BaselineChallenge/2/end/12/some'), 'split_size': DataArtifact('BaselineChallenge/2/end/12/split_size'), 'scoring': DataArtifact('BaselineChallenge/2/end/12/scoring'), 'kfold': DataArtifact('BaselineChallenge/2/end/12/kfold'), 'data': DataArtifact('BaselineChallenge/2/end/12/data')}\n",
      "---------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'ModelResult' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[352], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mproperty\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, value)\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m---------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(run\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mbaseline_result)\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/client/core.py:738\u001b[0m, in \u001b[0;36mMetaflowData.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 738\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_artifacts[name]\u001b[39m.\u001b[39;49mdata\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/client/core.py:906\u001b[0m, in \u001b[0;36mDataArtifact.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m meta \u001b[39m=\u001b[39m {\n\u001b[1;32m    896\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object[\u001b[39m\"\u001b[39m\u001b[39msha\u001b[39m\u001b[39m\"\u001b[39m]},\n\u001b[1;32m    897\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfo\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m     },\n\u001b[1;32m    904\u001b[0m }\n\u001b[1;32m    905\u001b[0m \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m:root:\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 906\u001b[0m     obj \u001b[39m=\u001b[39m filecache\u001b[39m.\u001b[39;49mget_artifact(ds_type, location[\u001b[39m6\u001b[39;49m:], meta, \u001b[39m*\u001b[39;49mcomponents)\n\u001b[1;32m    907\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39m# Older artifacts have a location information which we can use.\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     obj \u001b[39m=\u001b[39m filecache\u001b[39m.\u001b[39mget_artifact_by_location(\n\u001b[1;32m    910\u001b[0m         ds_type, location, meta, \u001b[39m*\u001b[39mcomponents\n\u001b[1;32m    911\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/client/filecache.py:207\u001b[0m, in \u001b[0;36mFileCache.get_artifact\u001b[0;34m(self, ds_type, ds_root, data_metadata, flow_name, run_id, step_name, task_id, name)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_artifact\u001b[39m(\n\u001b[1;32m    197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    198\u001b[0m     ds_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     name,\n\u001b[1;32m    206\u001b[0m ):\n\u001b[0;32m--> 207\u001b[0m     _, obj \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\n\u001b[1;32m    208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_artifacts(\n\u001b[1;32m    209\u001b[0m             ds_type,\n\u001b[1;32m    210\u001b[0m             ds_root,\n\u001b[1;32m    211\u001b[0m             data_metadata,\n\u001b[1;32m    212\u001b[0m             flow_name,\n\u001b[1;32m    213\u001b[0m             run_id,\n\u001b[1;32m    214\u001b[0m             step_name,\n\u001b[1;32m    215\u001b[0m             task_id,\n\u001b[1;32m    216\u001b[0m             [name],\n\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    219\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/mambaforge/envs/full-stack-metaflow-corise/lib/python3.10/site-packages/metaflow/datastore/task_datastore.py:370\u001b[0m, in \u001b[0;36mTaskDataStore.load_artifacts\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    365\u001b[0m names \u001b[39m=\u001b[39m to_load[key]\n\u001b[1;32m    366\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m names:\n\u001b[1;32m    367\u001b[0m     \u001b[39m# We unpickle everytime to have fully distinct objects (the user\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[39m# would not expect two artifacts with different names to actually\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[39m# be aliases of one another)\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[39myield\u001b[39;00m name, pickle\u001b[39m.\u001b[39;49mloads(blob)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'ModelResult' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "name = 'BaselineChallenge'\n",
    "run = Flow(name).latest_run\n",
    "print(run.successful)\n",
    "\n",
    "b = run.data.some\n",
    "\n",
    "print(\"Me\")\n",
    "print(b)\n",
    "type(b)\n",
    "\n",
    "type(run.data)\n",
    "\n",
    "for property, value in vars(run.data).items():\n",
    "    print(property, \":\", value)\n",
    "    print(\"---------\")\n",
    "\n",
    "print(run.data.baseline_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Mastering the Art of Anticipation: Failures and Remedies in ModaMetric's Machine Learning Journey\n",
    "\n",
    "In this task, your challenge is to step into the role of a foresightful data scientist at ModaMetric, where you'll be anticipating potential pitfalls in the sentiment analysis classifier project. Not just that, but you'll also be charting out strategies to steer clear of these hitches. Here's how you'll navigate through:\n",
    "\n",
    "### Step 1: Forecasting Potential Failure Modes\n",
    "\n",
    "The key to overcoming challenges is to anticipate them. Start by picturing possible failure scenarios from an engineering perspective. For instance, you might think about problems like overfitting to the training data or biases in the data. Remember, the first step to finding a solution is acknowledging the problem.\n",
    "\n",
    "1. Overfitting to training data\n",
    "1. Misspelled words / use of slang words\n",
    "1. Foreign language reviews \n",
    "1. Review may reflect factors other than product satisfaction - e.g. price, fulfillment. \n",
    "1. Annotating reviews instead of relying on ratings; annotating can be expensive and slow and may result in disagreements between annotators \n",
    "\n",
    "\n",
    "### Step 2: Strategizing to Mitigate Failure Modes\n",
    "\n",
    "Having identified the potential obstacles, your next task is to devise counter-strategies. Consider what steps you'd take to address the problem if it arises. For instance, to counter overfitting, you could employ regularization techniques such as L1 or L2 regularization. Think of this step as drawing up a contingency plan.\n",
    "\n",
    "1. Overfitting can be mitigated by early stopping, regularization etc.\n",
    "1. An ML algorithm could be developed to identify reviews for which the sentiment may not be certain; these reviews could be sent to annotators to assign a sentiment rating instead of sending all reviews in the training/test set. \n",
    "1. A language detection algorithm could be used to identify non-English language reviews and sequester these from training. Eventually, after enough reviews accumulate in a particular language, the model could be enhanced to support this additional language. \n",
    "1. Use of spelling correction tools \n",
    "\n",
    "### Step 3: Planning Ahead to Dodge Failure Modes\n",
    "\n",
    "Beyond reactive strategies, you also need a proactive plan. What could you have done at the outset to avoid these potential pitfalls? Could you have collected a more diverse dataset to reduce bias? Or experimented with different model architectures? The goal is to minimize reactive measures and maximize foresight.\n",
    "\n",
    "This task emphasizes the importance of anticipation in machine learning projects. By identifying possible failure modes and crafting mitigation strategies, you'll be preparing yourself for a smooth-sailing machine learning journey at ModaMetric.\n",
    "\n",
    "1. Annotating some reviews based on mimatches between product reviews and the sentiment of the corresponding reviews \n",
    "1. Pre-processing reviews for spelling errors and dropping words (e.g. product names) which will not be useful for sentiment analysis \n",
    "1. Adopt a wide vocabulary (perhaps by looking at public datasets for product reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Bringing ML Results to Life: ModaMetric's Visualization Adventure with MF Cards\n",
    "\n",
    "It's time for you to go beyond the code and transform data into a visual narrative. As a member of ModaMetric's data science team, your next mission is to enhance the existing flow in your `baseline_challenge.py` file. Add a new layer that gathers the results from all the hyperparameter tuning jobs. But that's not all - you're also going to breathe life into this aggregated data by creating a data visualization using Metaflow cards. Here's what you need to do:\n",
    "\n",
    "### Step 1: Extend Your Flow\n",
    "\n",
    "Your first challenge is to add another level to your existing `baseline_challenge.py` file. This new addition should be able to collate all the outcomes from your various hyperparameter tuning jobs. \n",
    "\n",
    "### Step 2: Log Results and Create Data Visualization\n",
    "\n",
    "Once you've collected the outcomes, it's time to log the results in a structured way. Then, you're going to take this information and create a compelling data visualization using Metaflow cards. Remember, a picture is worth a thousand numbers. With these visual insights, you'll be enabling ModaMetric to understand the performance of your machine learning model in a glance.\n",
    "\n",
    "This task is your opportunity to blend your technical skills with creative thinking. By visualizing your ML results, you're not only making the data more digestible but also contributing to ModaMetric's data-driven decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting baseline_challenge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile baseline_challenge.py\n",
    "# TODO: In this cell, write your BaselineChallenge flow in the baseline_challenge.py file.\n",
    "\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Flow,\n",
    "    current,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current,\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact, Image\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# TODO: Define your labeling function here.\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelResult:\n",
    "    \"A custom struct for storing model evaluation results.\"\n",
    "    name: None\n",
    "    params: None\n",
    "    pathspec: None\n",
    "    acc: None\n",
    "    rocauc: None\n",
    "\n",
    "\n",
    "class BaselineChallenge(FlowSpec):\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    data = IncludeFile(\"data\", default=\"Womens Clothing E-Commerce Reviews.csv\")\n",
    "    kfold = Parameter(\"k\", default=5)\n",
    "    scoring = Parameter(\"scoring\", default=\"accuracy\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # load dataset packaged with the flow.\n",
    "        # this technique is convenient when working with small datasets that need to move to remove tasks.\n",
    "        # TODO: load the data.\n",
    "        df = pd.read_csv(io.StringIO(self.data), index_col=0)\n",
    "        # Look up a few lines to the IncludeFile('data', default='Womens Clothing E-Commerce Reviews.csv').\n",
    "        # You can find documentation on IncludeFile here: https://docs.metaflow.org/scaling/data#data-in-local-files\n",
    "\n",
    "        # filter down to reviews and labels\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df = df[~df.review_text.isna()]\n",
    "        df[\"review\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "        # split the data 80/20, or by using the flow's split-sz CLI argument\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, test_size=self.split_size)\n",
    "        print(f\"num of rows in train set: {self.traindf.shape[0]}\")\n",
    "        print(f\"num of rows in validation set: {self.valdf.shape[0]}\")\n",
    "\n",
    "        self.next(self.baseline, self.model)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "        self._name = \"baseline\"\n",
    "        params = \"Always predict 1\"\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        # TODO: predict the majority class\n",
    "        predictions = [1] * len(self.valdf)\n",
    "        # TODO: return the accuracy_score of these predictions\n",
    "        acc = accuracy_score(self.valdf.label, predictions)\n",
    "\n",
    "        # TODO: return the roc_auc_score of these predictions\n",
    "        rocauc = roc_auc_score(self.valdf.label, predictions)\n",
    "        self.result = ModelResult(\"Baseline\", params, pathspec, acc, rocauc)\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "    @step\n",
    "    def model(self):\n",
    "        # TODO: import your model if it is defined in another file.\n",
    "        from model import NbowModel\n",
    "\n",
    "        self._name = \"model\"\n",
    "        # NOTE: If you followed the link above to find a custom model implementation,\n",
    "        # you will have noticed your model's vocab_sz hyperparameter.\n",
    "        # Too big of vocab_sz causes an error. Can you explain why?\n",
    "        self.hyperparam_set = [{\"vocab_sz\": 100}, {\"vocab_sz\": 300}, {\"vocab_sz\": 500}]\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        self.results = []\n",
    "        for params in self.hyperparam_set:\n",
    "            # TODO: instantiate your custom model here!\n",
    "            model = NbowModel(**params)  # TODO: instantiate your custom model here!\n",
    "            model.fit(X=self.df[\"review\"], y=self.df[\"label\"])\n",
    "            # TODO: evaluate your custom model in an equivalent way to accuracy_score.\n",
    "            acc = model.eval_acc(self.valdf.review.values, self.valdf.label) \n",
    "            # TODO: evaluate your custom model in an equivalent way to roc_auc_score.\n",
    "            rocauc = model.eval_rocauc(self.valdf.review.values, self.valdf.label) \n",
    "            self.results.append(\n",
    "                ModelResult(\n",
    "                    f\"NbowModel - vocab_sz: {params['vocab_sz']}\",\n",
    "                    params,\n",
    "                    pathspec,\n",
    "                    acc,\n",
    "                    rocauc,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "    def add_one(self, rows, result, df):\n",
    "        \"A helper function to load results.\"\n",
    "        rows.append(\n",
    "            [\n",
    "                Markdown(result.name),\n",
    "                Artifact(result.params),\n",
    "                Artifact(result.pathspec),\n",
    "                Artifact(result.acc),\n",
    "                Artifact(result.rocauc),\n",
    "            ]\n",
    "        )\n",
    "        df[\"name\"].append(result.name)\n",
    "        df[\"accuracy\"].append(result.acc)\n",
    "        return rows, df\n",
    "\n",
    "    @card(type=\"corise\")  # TODO: Set your card type to \"corise\".\n",
    "    # I wonder what other card types there are?\n",
    "    # https://docs.metaflow.org/metaflow/visualizing-results\n",
    "    # https://github.com/outerbounds/metaflow-card-altair/blob/main/altairflow.py\n",
    "    @step\n",
    "    def aggregate(self, inputs):\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib import rcParams\n",
    "\n",
    "        rcParams.update({\"figure.autolayout\": True})\n",
    "\n",
    "        rows = []\n",
    "        violin_plot_df = {\"name\": [], \"accuracy\": []}\n",
    "        for task in inputs:\n",
    "            if task._name == \"model\":\n",
    "                for result in task.results:\n",
    "                    print(result)\n",
    "                    rows, violin_plot_df = self.add_one(rows, result, violin_plot_df)\n",
    "            elif task._name == \"baseline\":\n",
    "                print(task.result)\n",
    "                rows, violin_plot_df = self.add_one(rows, task.result, violin_plot_df)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown task._name type. Cannot parse results.\")\n",
    "\n",
    "        current.card.append(Markdown(\"# All models from this flow run\"))\n",
    "\n",
    "        # TODO: Add a Table of the results to your card!\n",
    "        current.card.append(\n",
    "            Table(\n",
    "                rows,  # TODO: What goes here to populate the Table in the card?\n",
    "                headers=[\"Model name\", \"Params\", \"Task pathspec\", \"Accuracy\", \"ROCAUC\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        plt.xticks(rotation=40)\n",
    "        sns.violinplot(data=violin_plot_df, x=\"name\", y=\"accuracy\", ax=ax)\n",
    "\n",
    "        # TODO: Append the matplotlib fig to the card\n",
    "        # Docs: https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#showing-plots\n",
    "        current.card.append(Image.from_matplotlib(fig))\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BaselineChallenge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.7.2+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mBaselineChallenge\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mIncluding file ../data/Womens Clothing E-Commerce Reviews.csv of size 8MB \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:46.720 \u001b[0m\u001b[1mWorkflow starting (run-id 7), see it in the UI at https://ui-pw-906649423.outerbounds.dev/BaselineChallenge/7\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:46.979 \u001b[0m\u001b[32m[7/start/38 (pid 18180)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:51.139 \u001b[0m\u001b[32m[7/start/38 (pid 18180)] \u001b[0m\u001b[22mnum of rows in train set: 18112\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:54.756 \u001b[0m\u001b[32m[7/start/38 (pid 18180)] \u001b[0m\u001b[22mnum of rows in validation set: 4529\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:55.079 \u001b[0m\u001b[32m[7/start/38 (pid 18180)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:55.574 \u001b[0m\u001b[32m[7/baseline/39 (pid 18282)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:55.785 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:20:57.966 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22m2023-10-29 15:20:57.966467: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:01.806 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:01.806 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22m2023-10-29 15:21:01.806285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:02.288 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:02.289 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:02.769 \u001b[0m\u001b[32m[7/baseline/39 (pid 18282)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:03.562 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.7851 - val_loss: 0.4163 - val_accuracy: 0.8163\u001b[0m397 - accuracy: 0.40\n",
      "\u001b[35m2023-10-29 15:21:05.183 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4202 - accuracy: 0.8106 - val_loss: 0.4136 - val_accuracy: 0.8181\u001b[0m4 - accuracy: 0.78\n",
      "\u001b[35m2023-10-29 15:21:06.092 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8140 - val_loss: 0.4107 - val_accuracy: 0.8234\u001b[0m3 - accuracy: 0.84\n",
      "\u001b[35m2023-10-29 15:21:07.023 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8161 - val_loss: 0.4104 - val_accuracy: 0.8220\u001b[0m4 - accuracy: 0.78\n",
      "\u001b[35m2023-10-29 15:21:07.975 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4088 - accuracy: 0.8161 - val_loss: 0.4081 - val_accuracy: 0.8205\u001b[0m8 - accuracy: 0.78\n",
      "\u001b[35m2023-10-29 15:21:08.903 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4065 - accuracy: 0.8179 - val_loss: 0.4089 - val_accuracy: 0.8205\u001b[0m4 - accuracy: 0.87\n",
      "\u001b[35m2023-10-29 15:21:09.861 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8199 - val_loss: 0.4089 - val_accuracy: 0.8185\u001b[0m7 - accuracy: 0.81\n",
      "\u001b[35m2023-10-29 15:21:10.855 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8197 - val_loss: 0.4122 - val_accuracy: 0.8216\u001b[0m9 - accuracy: 0.87\n",
      "\u001b[35m2023-10-29 15:21:11.803 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8265 - val_loss: 0.4093 - val_accuracy: 0.8196\u001b[0m2 - accuracy: 0.78\n",
      "\u001b[35m2023-10-29 15:21:12.739 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8270 - val_loss: 0.4124 - val_accuracy: 0.8203\u001b[0m6 - accuracy: 0.87\n",
      "142/142 [==============================] - 0s 827us/step\u001b[0m)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: 11\n",
      "142/142 [==============================] - 0s 838us/step\u001b[0m)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-29 15:21:14.835 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:16.081 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:16.081 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 2ms/step - loss: 0.4023 - accuracy: 0.8246 - val_loss: 0.3557 - val_accuracy: 0.8501\u001b[0m850 - accuracy: 0.46\n",
      "\u001b[35m2023-10-29 15:21:17.635 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8461 - val_loss: 0.3518 - val_accuracy: 0.8503\u001b[0m4 - accuracy: 0.90\n",
      "\u001b[35m2023-10-29 15:21:18.637 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8520 - val_loss: 0.3495 - val_accuracy: 0.8538\u001b[0m7 - accuracy: 0.71\n",
      "\u001b[35m2023-10-29 15:21:19.651 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8562 - val_loss: 0.3480 - val_accuracy: 0.8569\u001b[0m7 - accuracy: 0.84\n",
      "\u001b[35m2023-10-29 15:21:20.663 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8578 - val_loss: 0.3493 - val_accuracy: 0.8538\u001b[0m9 - accuracy: 0.93\n",
      "\u001b[35m2023-10-29 15:21:21.635 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8594 - val_loss: 0.3516 - val_accuracy: 0.8527\u001b[0m1 - accuracy: 0.93\n",
      "\u001b[35m2023-10-29 15:21:22.608 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8650 - val_loss: 0.3513 - val_accuracy: 0.8534\u001b[0m1 - accuracy: 0.90\n",
      "\u001b[35m2023-10-29 15:21:23.600 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8689 - val_loss: 0.3596 - val_accuracy: 0.8529\u001b[0m9 - accuracy: 0.93\n",
      "\u001b[35m2023-10-29 15:21:24.596 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.8700 - val_loss: 0.3567 - val_accuracy: 0.8560\u001b[0m6 - accuracy: 0.90\n",
      "\u001b[35m2023-10-29 15:21:25.633 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8740 - val_loss: 0.3641 - val_accuracy: 0.8507\u001b[0m1 - accuracy: 0.81\n",
      "142/142 [==============================] - 0s 904us/step\u001b[0m)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "142/142 [==============================] - 0s 904us/step\u001b[0m)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-29 15:21:27.668 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:28.919 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:28.919 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 2ms/step - loss: 0.3825 - accuracy: 0.8348 - val_loss: 0.3388 - val_accuracy: 0.8620\u001b[0m091 - accuracy: 0.65\n",
      "\u001b[35m2023-10-29 15:21:30.595 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8582 - val_loss: 0.3394 - val_accuracy: 0.8605\u001b[0m2 - accuracy: 0.75\n",
      "\u001b[35m2023-10-29 15:21:31.687 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8636 - val_loss: 0.3368 - val_accuracy: 0.8605\u001b[0m3 - accuracy: 0.90\n",
      "\u001b[35m2023-10-29 15:21:33.038 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8631 - val_loss: 0.3377 - val_accuracy: 0.8591\u001b[0m3 - accuracy: 0.62\n",
      "\u001b[35m2023-10-29 15:21:34.075 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8678 - val_loss: 0.3385 - val_accuracy: 0.8589\u001b[0m6 - accuracy: 0.90\n",
      "\u001b[35m2023-10-29 15:21:35.123 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3069 - accuracy: 0.8738 - val_loss: 0.3453 - val_accuracy: 0.8547\u001b[0m8 - accuracy: 0.78\n",
      "\u001b[35m2023-10-29 15:21:36.170 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3010 - accuracy: 0.8775 - val_loss: 0.3444 - val_accuracy: 0.8613\u001b[0m6 - accuracy: 0.87\n",
      "\u001b[35m2023-10-29 15:21:37.243 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.8799 - val_loss: 0.3426 - val_accuracy: 0.8605\u001b[0m4 - accuracy: 0.81\n",
      "\u001b[35m2023-10-29 15:21:38.322 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8825 - val_loss: 0.3497 - val_accuracy: 0.8580\u001b[0m8 - accuracy: 0.96\n",
      "\u001b[35m2023-10-29 15:21:39.494 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8867 - val_loss: 0.3572 - val_accuracy: 0.8580\u001b[0m2 - accuracy: 0.96\n",
      "142/142 [==============================] - 0s 931us/step\u001b[0m)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "142/142 [==============================] - 0s 1ms/step\u001b[0m85)] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-29 15:21:45.144 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:45.477 \u001b[0m\u001b[32m[7/model/40 (pid 18285)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:45.986 \u001b[0m\u001b[32m[7/aggregate/41 (pid 19248)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:50.230 \u001b[0m\u001b[32m[7/aggregate/41 (pid 19248)] \u001b[0m\u001b[22mModelResult(name='Baseline', params='Always predict 1', pathspec='BaselineChallenge/7/baseline/39', acc=0.7621991609626849, rocauc=0.5)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:50.296 \u001b[0m\u001b[32m[7/aggregate/41 (pid 19248)] \u001b[0m\u001b[22mModelResult(name='NbowModel - vocab_sz: 100', params={'vocab_sz': 100}, pathspec='BaselineChallenge/7/model/40', acc=0.8363877235592846, rocauc=0.8732470834933741)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:50.296 \u001b[0m\u001b[32m[7/aggregate/41 (pid 19248)] \u001b[0m\u001b[22mModelResult(name='NbowModel - vocab_sz: 300', params={'vocab_sz': 300}, pathspec='BaselineChallenge/7/model/40', acc=0.8823139765952749, rocauc=0.9350057184294814)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:53.792 \u001b[0m\u001b[32m[7/aggregate/41 (pid 19248)] \u001b[0m\u001b[22mModelResult(name='NbowModel - vocab_sz: 500', params={'vocab_sz': 500}, pathspec='BaselineChallenge/7/model/40', acc=0.9066018988739236, rocauc=0.9544122013963081)\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:54.059 \u001b[0m\u001b[32m[7/aggregate/41 (pid 19248)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:54.393 \u001b[0m\u001b[32m[7/end/42 (pid 19329)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:57.404 \u001b[0m\u001b[32m[7/end/42 (pid 19329)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-29 15:21:57.528 \u001b[0m\u001b[1mDone! See the run in the UI at https://ui-pw-906649423.outerbounds.dev/BaselineChallenge/7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python baseline_challenge.py run --data \"../data/Womens Clothing E-Commerce Reviews.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Exploring Advanced Visualization Opportunities with MF Cards (Optional)\n",
    "\n",
    "As ModaMetric continues to thrive and grow, it's clear that basic visualizations won't be enough to understand the intricate dynamics of our e-commerce customer sentiment. We want to take our data storytelling to the next level. And you, as a valued member of our data science team, are the perfect person to lead this initiative.\n",
    "\n",
    "This optional task is an open invitation for you to really explore how you can leverage Metaflow's features to deliver a compelling, multidimensional story.\n",
    "\n",
    "### Step 1: Dive Deeper into Hyperparameter Tuning Insights\n",
    "\n",
    "While we have already visualized the results of the hyperparameter tuning, we believe there's more to unearth. Consider how you might visualize the correlation between specific hyperparameters and model performance, or how different hyperparameter combinations affect the training time.\n",
    "\n",
    "### Step 2: Unearth Hidden Trends in Customer Sentiment\n",
    "\n",
    "ModaMetric prides itself on delivering the best for our customers. Can we use our sentiment analysis data to learn more about our customer preferences? Try to create visualizations that show trends in sentiment across different clothing categories, times of year, or any other dimension you find interesting.\n",
    "\n",
    "### Step 3: Explore Advanced Visualization Techniques\n",
    "\n",
    "Metaflow can accommodate a wide range of data visualization techniques. This is your chance to showcase those advanced skills. Perhaps you could experiment with multi-panel plots, 3D visualizations, or interactive plots that let viewers explore the data for themselves. You can refer to this [blog post](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjJwOe55pqAAxXA6KACHTZzAsoQFnoECCAQAQ&url=https%3A%2F%2Fouterbounds.com%2Fblog%2Fintegrating-pythonic-visual-reports-into-ml-pipelines%2F&usg=AOvVaw2PY3huULq5xR3yZEQ1s-OL&opi=89978449) for more information about how you may do this. \n",
    "\n",
    "We're looking forward to seeing where your creativity and technical expertise can lead ModaMetric. Remember, there are no boundaries - the sky's the limit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
